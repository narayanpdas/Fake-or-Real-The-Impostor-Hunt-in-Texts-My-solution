{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":105874,"databundleVersionId":12964783,"sourceType":"competition"},{"sourceId":12726806,"sourceType":"datasetVersion","datasetId":8044196},{"sourceId":12740763,"sourceType":"datasetVersion","datasetId":8053707},{"sourceId":12741377,"sourceType":"datasetVersion","datasetId":8028993}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n# TRAIN_DATA_PATH = '/kaggle/input/fake-or-real-the-imposter-x-train/train_data.csv'\nTEST_DATA_PATH = '/kaggle/input/fake-or-real-the-imposter-x-train/test_data.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T05:09:01.476409Z","iopub.execute_input":"2025-08-12T05:09:01.477241Z","iopub.status.idle":"2025-08-12T05:09:01.480622Z","shell.execute_reply.started":"2025-08-12T05:09:01.477207Z","shell.execute_reply":"2025-08-12T05:09:01.480053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df = pd.read_csv(TRAIN_DATA_PATH)\nTEST_DATA_PATH = '/kaggle/input/fake-or-real-the-imposter-x-train/test_data.csv'\ntest_df = pd.read_csv(TEST_DATA_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T05:09:02.197073Z","iopub.execute_input":"2025-08-12T05:09:02.197723Z","iopub.status.idle":"2025-08-12T05:09:02.258248Z","shell.execute_reply.started":"2025-08-12T05:09:02.197698Z","shell.execute_reply":"2025-08-12T05:09:02.257679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Preparing the Data for our Deep Learning Model...**","metadata":{}},{"cell_type":"code","source":"import os \npath = '/kaggle/input/fake-or-real-the-impostor-hunt/data/train'\ntrain_df = []\nfor articles in os.listdir(path):\n    data_point = []\n    data_point.append(articles)\n    for text in os.listdir(path+'/'+articles):\n        with open(path+'/'+articles+'/'+text,'r') as file:\n            contents = file.read()\n            data_point.append(contents)\n            file.close()\n    train_df.append(data_point)\ntrain_df[:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T04:33:38.923721Z","iopub.execute_input":"2025-08-12T04:33:38.924028Z","iopub.status.idle":"2025-08-12T04:33:40.213869Z","shell.execute_reply.started":"2025-08-12T04:33:38.924008Z","shell.execute_reply":"2025-08-12T04:33:40.213047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.DataFrame(train_df)\ntrain_df.columns = ['article_number','text_2','text_1']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T04:34:23.613232Z","iopub.execute_input":"2025-08-12T04:34:23.613539Z","iopub.status.idle":"2025-08-12T04:34:23.618720Z","shell.execute_reply.started":"2025-08-12T04:34:23.613516Z","shell.execute_reply":"2025-08-12T04:34:23.617814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['id'] = train_df['article_number'].str.split('_').str[1].astype(int)\ntrain_df = train_df.sort_values(by='id').reset_index(drop=True)\n\ntrain_labels_path = '/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv'\ntrain_labels = pd.read_csv(train_labels_path)\nprint(len(train_labels))\n\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', None)\n\ntrain_labels.drop(index = [10,14],inplace=True)\ntrain_df.drop(index = [10,14],inplace=True)\n\nprint(len(train_labels),len(train_df))\n\ntrain_df_total = train_df\ntrain_df_total['labels'] = train_labels['real_text_id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T04:36:59.784336Z","iopub.execute_input":"2025-08-12T04:36:59.784939Z","iopub.status.idle":"2025-08-12T04:36:59.789582Z","shell.execute_reply.started":"2025-08-12T04:36:59.784914Z","shell.execute_reply":"2025-08-12T04:36:59.788599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RUN FROM HERE FOR TRAINING THE TRANSFORMER MODEL ","metadata":{}},{"cell_type":"code","source":"train_dataset_path = '/kaggle/input/fake-or-real-the-imposter-x-train/train_dataset.csv'\ntrain_dataset = pd.read_csv(train_dataset_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:25.365459Z","iopub.execute_input":"2025-08-12T06:25:25.366224Z","iopub.status.idle":"2025-08-12T06:25:25.390896Z","shell.execute_reply.started":"2025-08-12T06:25:25.366182Z","shell.execute_reply":"2025-08-12T06:25:25.390195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:27.297589Z","iopub.execute_input":"2025-08-12T06:25:27.298282Z","iopub.status.idle":"2025-08-12T06:25:27.318383Z","shell.execute_reply.started":"2025-08-12T06:25:27.298248Z","shell.execute_reply":"2025-08-12T06:25:27.317792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:29.410884Z","iopub.execute_input":"2025-08-12T06:25:29.411153Z","iopub.status.idle":"2025-08-12T06:25:29.414709Z","shell.execute_reply.started":"2025-08-12T06:25:29.411134Z","shell.execute_reply":"2025-08-12T06:25:29.414092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf['final_text1'] = df['text_1']\ndf['final_text2'] = df['text_2']\ndf['final_label'] = np.where(df['labels'] == 1, 1, 0) # 1 if text1 is real, 0 otherwise\n\n# Find rows where text2 was the real one (original label == 2)\nswap_indices = df['labels'] == 2\n\n# Swap text1 and text2 for these rows\ndf.loc[swap_indices, 'final_text1'] = df.loc[swap_indices, 'text_2']\ndf.loc[swap_indices, 'final_text2'] = df.loc[swap_indices, 'text_1']\n\n# Now, 'final_text1' is always the \"real\" text, 'final_text2' is the \"fake\" text.\n# The label can be simplified. Let's create a balanced dataset.\n# We'll create two examples for each original row to avoid positional bias.\n\npart1_df = pd.DataFrame({\n    'text1': df['final_text1'],\n    'text2': df['final_text2'],\n    'label': 1  # In this order, the first text is real\n})\n\npart2_df = pd.DataFrame({\n    'text1': df['final_text2'], # Fake text is now first\n    'text2': df['final_text1'],\n    'label': 0  # In this order, the first text is not real\n})\n\nfinal_df = pd.concat([part1_df, part2_df], ignore_index=True)\n\n# Split the data\ntrain_df, val_df = train_test_split(final_df, test_size=0.2, random_state=42, stratify=final_df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:32.180679Z","iopub.execute_input":"2025-08-12T06:25:32.180935Z","iopub.status.idle":"2025-08-12T06:25:32.228942Z","shell.execute_reply.started":"2025-08-12T06:25:32.180915Z","shell.execute_reply":"2025-08-12T06:25:32.228430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertTokenizer, TFAutoModelForSequenceClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:34.246629Z","iopub.execute_input":"2025-08-12T06:25:34.246889Z","iopub.status.idle":"2025-08-12T06:25:34.250566Z","shell.execute_reply.started":"2025-08-12T06:25:34.246869Z","shell.execute_reply":"2025-08-12T06:25:34.249781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = 'roberta-base'\ntokenizer = BertTokenizer.from_pretrained(model_name)\n\n# Tokenize the data\n# The tokenizer takes the two lists of texts directly.\ntrain_encodings = tokenizer(\n    train_df['text1'].tolist(),\n    train_df['text2'].tolist(),\n    truncation=True,\n    padding=True,\n    max_length=512\n)\n\nval_encodings = tokenizer(\n    val_df['text1'].tolist(),\n    val_df['text2'].tolist(),\n    truncation=True,\n    padding=True,\n    max_length=512\n)\n\n# Extract labels\ntrain_labels = train_df['label'].values\nval_labels = val_df['label'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:43.588658Z","iopub.execute_input":"2025-08-12T06:25:43.589367Z","iopub.status.idle":"2025-08-12T06:25:47.094630Z","shell.execute_reply.started":"2025-08-12T06:25:43.589339Z","shell.execute_reply":"2025-08-12T06:25:47.094058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n# Create the datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),\n    train_labels\n))\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(val_encodings),\n    val_labels\n))\n\n# Shuffle and batch the datasets\nBATCH_SIZE = 8\ntrain_dataset = train_dataset.shuffle(len(train_df)).batch(BATCH_SIZE)\nval_dataset = val_dataset.batch(BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:25:47.095765Z","iopub.execute_input":"2025-08-12T06:25:47.096351Z","iopub.status.idle":"2025-08-12T06:25:47.868482Z","shell.execute_reply.started":"2025-08-12T06:25:47.096329Z","shell.execute_reply":"2025-08-12T06:25:47.867946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the pre-trained BERT model for sequence classification\n# We use num_labels=1 for binary classification with a sigmoid output.\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n\n# Compile the model\n# It's crucial to use a very low learning rate for fine-tuning.\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Use from_logits=True for stability\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\n# Train the model\nNUM_EPOCHS = 5\nhistory = model.fit(\n    train_dataset,\n    epochs=NUM_EPOCHS,\n    validation_data=val_dataset\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:26:32.084821Z","iopub.execute_input":"2025-08-12T06:26:32.085091Z","iopub.status.idle":"2025-08-12T06:29:09.676837Z","shell.execute_reply.started":"2025-08-12T06:26:32.085073Z","shell.execute_reply":"2025-08-12T06:29:09.676282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\ndef plot_training_history(history):\n    \"\"\"\n    Plots the training and validation loss/accuracy curves and prints a summary.\n\n    Args:\n        history: A Keras History object returned by the model.fit() method.\n    \"\"\"\n    # Convert the history.history dict to a pandas DataFrame\n    hist_df = pd.DataFrame(history.history)\n    \n    # --- Print a statistical summary ---\n    # Find the epoch with the best validation accuracy\n    best_epoch_acc = hist_df['val_accuracy'].idxmax() + 1\n    best_val_acc = hist_df['val_accuracy'].max()\n    \n    # Find the epoch with the best validation loss\n    best_epoch_loss = hist_df['val_loss'].idxmin() + 1\n    best_val_loss = hist_df['val_loss'].min()\n\n    print(\"--- Training Summary ---\")\n    print(f\"Best Validation Accuracy: {best_val_acc:.4f} at epoch {best_epoch_acc}\")\n    print(f\"Lowest Validation Loss: {best_val_loss:.4f} at epoch {best_epoch_loss}\")\n    print(\"------------------------\\n\")\n\n    # --- Plot the training curves ---\n    sns.set_style(\"whitegrid\")\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n    # Plot Loss\n    axes[0].plot(hist_df.index + 1, hist_df['loss'], label='Training Loss', color='blue')\n    axes[0].plot(hist_df.index + 1, hist_df['val_loss'], label='Validation Loss', color='orange')\n    axes[0].set_title('Loss Curves', fontsize=14)\n    axes[0].set_xlabel('Epoch')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n\n    # Plot Accuracy\n    axes[1].plot(hist_df.index + 1, hist_df['accuracy'], label='Training Accuracy', color='blue')\n    axes[1].plot(hist_df.index + 1, hist_df['val_accuracy'], label='Validation Accuracy', color='orange')\n    axes[1].set_title('Accuracy Curves', fontsize=14)\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:29:09.678001Z","iopub.execute_input":"2025-08-12T06:29:09.678314Z","iopub.status.idle":"2025-08-12T06:29:09.903632Z","shell.execute_reply.started":"2025-08-12T06:29:09.678288Z","shell.execute_reply":"2025-08-12T06:29:09.902928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:29:14.062038Z","iopub.execute_input":"2025-08-12T06:29:14.063028Z","iopub.status.idle":"2025-08-12T06:29:14.710079Z","shell.execute_reply.started":"2025-08-12T06:29:14.063002Z","shell.execute_reply":"2025-08-12T06:29:14.709369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a path to save the model\nsave_path = './my_bert_tf_model'\n\n# Save the model's learned weights and configuration\nmodel.save_pretrained(save_path)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_path)\n\nprint(f\"Model and tokenizer saved to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:29:32.932985Z","iopub.execute_input":"2025-08-12T06:29:32.933745Z","iopub.status.idle":"2025-08-12T06:29:34.217511Z","shell.execute_reply.started":"2025-08-12T06:29:32.933721Z","shell.execute_reply":"2025-08-12T06:29:34.216708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r bert_tf_model.zip /kaggle/working/my_bert_tf_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:31:01.205402Z","iopub.execute_input":"2025-08-12T06:31:01.206156Z","iopub.status.idle":"2025-08-12T06:31:24.376445Z","shell.execute_reply.started":"2025-08-12T06:31:01.206121Z","shell.execute_reply":"2025-08-12T06:31:24.375530Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RUN FROM HERE FOR ONLY SCORE CHECKING\n# Checking With Both Machine Learning Esemble Model and Transformer model\n### Assigned weights to each of the model's prediction probability based on their score on test_data\n","metadata":{}},{"cell_type":"code","source":"import joblib\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom transformers import logging\nTEST_DATA_PATH = '/kaggle/input/fake-or-real-the-imposter-x-train/test_data.csv'\ntest_df = pd.read_csv(TEST_DATA_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:39:16.930508Z","iopub.execute_input":"2025-08-12T06:39:16.931451Z","iopub.status.idle":"2025-08-12T06:39:17.010007Z","shell.execute_reply.started":"2025-08-12T06:39:16.931414Z","shell.execute_reply":"2025-08-12T06:39:17.009385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Suppress the benign tokenizer warning for cleaner output\nlogging.set_verbosity_error()\n\ndef predict_hybrid_ensemble(\n    classical_models, \n    transformer_model, \n    transformer_tokenizer, \n    test_df, \n    weights,\n    max_length=512,\n    batch_size=32,\n    inverse_classical=False\n):\n    \"\"\"\n    Generates predictions by blending a classical ensemble and a transformer model.\n\n    Args:\n        classical_models (list): A list of loaded scikit-learn pipeline models.\n        transformer_model: The fine-tuned Hugging Face TensorFlow model.\n        transformer_tokenizer: The corresponding tokenizer.\n        test_df (pd.DataFrame): The test DataFrame with 'text1' and 'text2' columns.\n        weights (tuple): A tuple of (classical_weight, transformer_weight), e.g., (0.5, 0.5).\n        max_length (int): Max sequence length for the tokenizer.\n        batch_size (int): Batch size for transformer inference.\n\n    Returns:\n        np.array: An array of final predictions (1s and 2s).\n    \"\"\"\n    print(\"--- Starting Hybrid Ensemble Prediction ---\")\n    \n    # --- Step 1: Get Predictions from the Classical Ensemble ---\n    print(\"Step 1: Getting predictions from classical models...\")\n    all_text_1s = test_df['text_1'].fillna('').tolist()\n    all_text_2s = test_df['text_2'].fillna('').tolist()\n    \n    classical_probas_t1 = [model.predict_proba(all_text_1s)[:, 1] for model in classical_models]\n    classical_probas_t2 = [model.predict_proba(all_text_2s)[:, 1] for model in classical_models]\n    \n    # Average the probabilities from the classical models\n    avg_classical_prob_t1 = np.mean(classical_probas_t1, axis=0)\n    avg_classical_prob_t2 = np.mean(classical_probas_t2, axis=0)\n    \n    # The final classical probability is the one for text1\n    classical_final_probs = np.where(avg_classical_prob_t1 > avg_classical_prob_t2, avg_classical_prob_t1, 1 - avg_classical_prob_t2)\n    if inverse_classical==True:\n        print('Inversing the Classical Models Probabilites.\\n')\n        classical_final_probs = 1 - classical_final_probs\n\n    # --- Step 2: Get Predictions from the Transformer Model ---\n    print(\"Step 2: Getting predictions from the transformer model...\")\n    test_encodings = transformer_tokenizer(\n        all_text_1s,\n        all_text_2s,\n        truncation=True,\n        padding=True,\n        max_length=max_length\n    )\n    test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_encodings)).batch(batch_size)\n    \n    logits = transformer_model.predict(test_dataset).logits\n    transformer_final_probs = tf.nn.sigmoid(logits).numpy().flatten()\n    \n\n    # --- Step 3: Blend the Probabilities ---\n    print(\"Step 3: Blending model probabilities...\")\n    weight_classical, weight_transformer = weights\n    classical_final_probs_np = np.array(classical_final_probs)\n    transformer_final_probs_np = np.array(transformer_final_probs)\n    blended_probs = (weight_classical * classical_final_probs) + (weight_transformer * transformer_final_probs)\n\n    \n    # --- Step 4: Make Final Predictions ---\n    print(\"Step 4: Generating final labels...\")\n    final_predictions = np.where(blended_probs > 0.5, 1, 2)\n    \n    print(\"--- Prediction process finished. ---\")\n    return final_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:55:54.502123Z","iopub.execute_input":"2025-08-12T06:55:54.502453Z","iopub.status.idle":"2025-08-12T06:55:54.512125Z","shell.execute_reply.started":"2025-08-12T06:55:54.502430Z","shell.execute_reply":"2025-08-12T06:55:54.511247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values in text1:\", test_df['text_1'].isnull().sum())\nprint(\"Missing values in text2:\", test_df['text_2'].isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:14:52.686200Z","iopub.execute_input":"2025-08-12T06:14:52.686526Z","iopub.status.idle":"2025-08-12T06:14:52.697216Z","shell.execute_reply.started":"2025-08-12T06:14:52.686505Z","shell.execute_reply":"2025-08-12T06:14:52.696354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nimport os\nfrom transformers import BertTokenizer, TFAutoModelForSequenceClassification\nMODEL_PATH = '/kaggle/input/tf-bert-model-for-fake-or-real-the-imposter-compt'\ntransformer_model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\ntransformer_tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\nclassical_models_path = '/kaggle/input/best-machine-learning-models-for-this-dataset'\nclassical_models = []\nfor model in os.listdir(classical_models_path):\n    classical_models.append(joblib.load(classical_models_path+'/'+model))\nscore_classical = 0.84024\nscore_transformer = 0.83195\ntotal_score = score_classical + score_transformer\nweights = (score_classical / total_score, score_transformer / total_score)\nprint(f\"Using weights: Classical={weights[0]:.2f}, Transformer={weights[1]:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:39:35.226980Z","iopub.execute_input":"2025-08-12T06:39:35.227322Z","iopub.status.idle":"2025-08-12T06:39:40.808063Z","shell.execute_reply.started":"2025-08-12T06:39:35.227298Z","shell.execute_reply":"2025-08-12T06:39:40.807330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_predictions = predict_hybrid_ensemble(\n    classical_models=classical_models,\n    transformer_model=transformer_model,\n    transformer_tokenizer=transformer_tokenizer,\n    test_df=test_df,\n    weights=weights, \n    inverse_classical=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:55:59.293107Z","iopub.execute_input":"2025-08-12T06:55:59.293847Z","iopub.status.idle":"2025-08-12T06:57:01.501381Z","shell.execute_reply.started":"2025-08-12T06:55:59.293812Z","shell.execute_reply":"2025-08-12T06:57:01.500519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_submission_csv(results):\n    df_results = pd.DataFrame(results)\n    output_df = df_results.copy()\n    output_df.columns = ['real_text_id']\n    output_df.reset_index(inplace=True)\n    output_df.rename(columns={'index': 'id'}, inplace=True)\n    output_df.to_csv('sample_submission.csv', index=False)\n    return output_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:57:29.914821Z","iopub.execute_input":"2025-08-12T06:57:29.915089Z","iopub.status.idle":"2025-08-12T06:57:29.919644Z","shell.execute_reply.started":"2025-08-12T06:57:29.915071Z","shell.execute_reply":"2025-08-12T06:57:29.918892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"make_submission_csv(final_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:57:31.736839Z","iopub.execute_input":"2025-08-12T06:57:31.737384Z","iopub.status.idle":"2025-08-12T06:57:31.748581Z","shell.execute_reply.started":"2025-08-12T06:57:31.737358Z","shell.execute_reply":"2025-08-12T06:57:31.747934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Psuedo Labelling the TEST DATA for Higher Amount of training data","metadata":{}},{"cell_type":"code","source":"# Suppress the benign tokenizer warning for cleaner output\nlogging.set_verbosity_error()\n\ndef predict_hybrid_ensemble_proba(\n    classical_models, \n    transformer_model, \n    transformer_tokenizer, \n    test_df, \n    weights,\n    max_length=512,\n    batch_size=32,\n    inverse_classical=False\n):\n    \"\"\"\n    Generates predictions by blending a classical ensemble and a transformer model.\n\n    Args:\n        classical_models (list): A list of loaded scikit-learn pipeline models.\n        transformer_model: The fine-tuned Hugging Face TensorFlow model.\n        transformer_tokenizer: The corresponding tokenizer.\n        test_df (pd.DataFrame): The test DataFrame with 'text1' and 'text2' columns.\n        weights (tuple): A tuple of (classical_weight, transformer_weight), e.g., (0.5, 0.5).\n        max_length (int): Max sequence length for the tokenizer.\n        batch_size (int): Batch size for transformer inference.\n\n    Returns:\n        np.array: An array of final predictions (1s and 2s).\n    \"\"\"\n    print(\"--- Starting Hybrid Ensemble Prediction ---\")\n    \n    # --- Step 1: Get Predictions from the Classical Ensemble ---\n    print(\"Step 1: Getting predictions from classical models...\")\n    all_text_1s = test_df['text_1'].fillna('').tolist()\n    all_text_2s = test_df['text_2'].fillna('').tolist()\n    \n    classical_probas_t1 = [model.predict_proba(all_text_1s)[:, 1] for model in classical_models]\n    classical_probas_t2 = [model.predict_proba(all_text_2s)[:, 1] for model in classical_models]\n    \n    # Average the probabilities from the classical models\n    avg_classical_prob_t1 = np.mean(classical_probas_t1, axis=0)\n    avg_classical_prob_t2 = np.mean(classical_probas_t2, axis=0)\n    \n    # The final classical probability is the one for text1\n    classical_final_probs = np.where(avg_classical_prob_t1 > avg_classical_prob_t2, avg_classical_prob_t1, 1 - avg_classical_prob_t2)\n    if inverse_classical==True:\n        print('Inversing the Classical Models Probabilites.\\n')\n        classical_final_probs = 1 - classical_final_probs\n\n    # --- Step 2: Get Predictions from the Transformer Model ---\n    print(\"Step 2: Getting predictions from the transformer model...\")\n    test_encodings = transformer_tokenizer(\n        all_text_1s,\n        all_text_2s,\n        truncation=True,\n        padding=True,\n        max_length=max_length\n    )\n    test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_encodings)).batch(batch_size)\n    \n    logits = transformer_model.predict(test_dataset).logits\n    transformer_final_probs = tf.nn.sigmoid(logits).numpy().flatten()\n    \n\n    # --- Step 3: Blend the Probabilities ---\n    print(\"Step 3: Blending model probabilities...\")\n    weight_classical, weight_transformer = weights\n    classical_final_probs_np = np.array(classical_final_probs)\n    transformer_final_probs_np = np.array(transformer_final_probs)\n    blended_probs = (weight_classical * classical_final_probs) + (weight_transformer * transformer_final_probs)\n    \n    print(\"--- Prediction process finished. ---\")\n    return blended_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:16:34.324515Z","iopub.execute_input":"2025-08-12T07:16:34.325080Z","iopub.status.idle":"2025-08-12T07:16:34.333462Z","shell.execute_reply.started":"2025-08-12T07:16:34.325053Z","shell.execute_reply":"2025-08-12T07:16:34.332630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pseudo_probabilities = predict_hybrid_ensemble_proba(\n    classical_models=classical_models,\n    transformer_model=transformer_model,\n    transformer_tokenizer=transformer_tokenizer,\n    test_df=test_df,\n    weights=weights, \n    inverse_classical=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:18:47.963977Z","iopub.execute_input":"2025-08-12T07:18:47.964272Z","iopub.status.idle":"2025-08-12T07:19:49.966747Z","shell.execute_reply.started":"2025-08-12T07:18:47.964251Z","shell.execute_reply":"2025-08-12T07:19:49.966108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assume 'pseudo_probabilities' is the array of your blended probabilities\nplt.figure(figsize=(10, 6))\nsns.histplot(pseudo_probabilities, bins=50)\nplt.title('Distribution of Prediction Probabilities on Test Set')\nplt.xlabel('Predicted Probability (Confidence)')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:23:54.312281Z","iopub.execute_input":"2025-08-12T07:23:54.312815Z","iopub.status.idle":"2025-08-12T07:23:54.571269Z","shell.execute_reply.started":"2025-08-12T07:23:54.312788Z","shell.execute_reply":"2025-08-12T07:23:54.570509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confidence_threshold = 0.90 # 90% confidence\n\n# This checks for probabilities > 0.90 OR < 0.10 (which is 1 - 0.90)\nhigh_confidence_indices = np.where(\n    (pseudo_probabilities > confidence_threshold) | (pseudo_probabilities < (1 - confidence_threshold))\n)[0]\n\nprint(f\"Samples found with >90% or <10% probability: {len(high_confidence_indices)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:26:45.496363Z","iopub.execute_input":"2025-08-12T07:26:45.496662Z","iopub.status.idle":"2025-08-12T07:26:45.502159Z","shell.execute_reply.started":"2025-08-12T07:26:45.496639Z","shell.execute_reply":"2025-08-12T07:26:45.501250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confidence_threshold = 0.90\n\nhigh_confidence_indices = np.where(\n    (pseudo_probabilities > confidence_threshold) | (pseudo_probabilities < (1 - confidence_threshold))\n)[0]\n\npseudo_df = test_df.iloc[high_confidence_indices].copy()\nconfident_probs = pseudo_probabilities[high_confidence_indices]\n\n# Assign the pseudo-labels (1 if prob > 0.5, else 0)\npseudo_df['label'] = np.where(confident_probs > 0.5, 1, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:35:27.059570Z","iopub.execute_input":"2025-08-12T07:35:27.060277Z","iopub.status.idle":"2025-08-12T07:35:27.066253Z","shell.execute_reply.started":"2025-08-12T07:35:27.060255Z","shell.execute_reply":"2025-08-12T07:35:27.065594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pseudo_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:35:28.502498Z","iopub.execute_input":"2025-08-12T07:35:28.503362Z","iopub.status.idle":"2025-08-12T07:35:28.511259Z","shell.execute_reply.started":"2025-08-12T07:35:28.503324Z","shell.execute_reply":"2025-08-12T07:35:28.510575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(pseudo_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:35:35.179617Z","iopub.execute_input":"2025-08-12T07:35:35.179853Z","iopub.status.idle":"2025-08-12T07:35:35.184589Z","shell.execute_reply.started":"2025-08-12T07:35:35.179836Z","shell.execute_reply":"2025-08-12T07:35:35.183792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pseudo_df.to_csv('psuedo_data(from_mix_ml_and_BERT)_1.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:36:29.206991Z","iopub.execute_input":"2025-08-12T07:36:29.207311Z","iopub.status.idle":"2025-08-12T07:36:29.248160Z","shell.execute_reply.started":"2025-08-12T07:36:29.207285Z","shell.execute_reply":"2025-08-12T07:36:29.247259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}